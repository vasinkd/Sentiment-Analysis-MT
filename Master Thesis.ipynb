{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as etree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim import corpora, models\n",
    "\n",
    "from sklearn import model_selection, pipeline, preprocessing, metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import jamspell\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from natasha import OrganisationExtractor, LocationExtractor\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Изучение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_as_pd(doc): \n",
    "    tree = etree.parse(doc)\n",
    "    root = tree.getroot()\n",
    "    root = root[1]\n",
    "    data = []\n",
    "    for tweet in root:\n",
    "        row = {}\n",
    "        for feature in tweet:\n",
    "            row[feature.attrib[\"name\"]] = feature.text\n",
    "        data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_banks = \"Corpuses/SentiRuEval/bank_train_2016.xml\"\n",
    "test_banks = \"Corpuses/SentiRuEval/banks_test_etalon.xml\"\n",
    "\n",
    "X_train_banks = pd.DataFrame.from_dict(read_xml_as_pd(train_banks))[[\"text\"]].values.flatten()\n",
    "y_train_banks = pd.DataFrame.from_dict(read_xml_as_pd(train_banks)).drop([\"id\", \"twitid\", \"date\", \"text\"], 1)\n",
    "X_test_banks = pd.DataFrame.from_dict(read_xml_as_pd(test_banks))[[\"text\"]].values.flatten()\n",
    "y_test_banks = pd.DataFrame.from_dict(read_xml_as_pd(test_banks)).drop([\"id\", \"twitid\", \"date\", \"text\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#Автокредит в россельхозбанк в череповце'\n",
      " 'RT @thomasabiloxuz: http://t.co/GTfMwSQQ2c #Кредитный калькулятор россельхозбанк 2012'\n",
      " '#Автокредит в россельхозбанк 2012 http://t.co/9jc1OCzyv2'\n",
      " 'RT @ronaldisogacoq: #Кредитные карты россельхозбанк http://t.co/BZTF5Cuk4W'\n",
      " 'RT @anthonyogihulaf: #Кредиты в россельхозбанке ижевск http://t.co/GdqH1k0GlC'\n",
      " '#Аккредитация страховых компаний в россельхозбанке'\n",
      " 'RT @74Emtsov: #Россельхозбанк саранск кредитные программа гараж http://t.co/HNENQPRAJ9'\n",
      " '#Автокредит г барнаул россельхозбанк http://t.co/Bo5GAYm9ZO'\n",
      " 'http://t.co/AFunnXczvo #Автокредит калькулятор россельхозбанк'\n",
      " 'http://t.co/dVvbEAStbh #Автокредит в нальчике россельхозбанк']\n"
     ]
    }
   ],
   "source": [
    "print(X_test_banks[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tkk = \"Corpuses/SentiRuEval/tkk_train_2016.xml\"\n",
    "test_tkk = \"Corpuses/SentiRuEval/tkk_test_etalon.xml\"\n",
    "\n",
    "X_train_tkk = pd.DataFrame.from_dict(read_xml_as_pd(train_tkk))[[\"text\"]].values.flatten()\n",
    "y_train_tkk = pd.DataFrame.from_dict(read_xml_as_pd(train_tkk)).drop([\"id\", \"twitid\", \"date\", \"text\"], 1)\n",
    "X_test_tkk = pd.DataFrame.from_dict(read_xml_as_pd(test_tkk))[[\"text\"]].values.flatten()\n",
    "y_test_tkk = pd.DataFrame.from_dict(read_xml_as_pd(test_tkk)).drop([\"id\", \"twitid\", \"date\", \"text\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9392,) (9392, 8) (3313,) (3313, 8)\n",
      "(8643,) (8643, 7) (2247,) (2247, 7)\n"
     ]
    }
   ],
   "source": [
    "# Объем доступных данных\n",
    "print(X_train_banks.shape, y_train_banks.shape, X_test_banks.shape,  y_test_banks.shape)\n",
    "print(X_train_tkk.shape, y_train_tkk.shape, X_test_tkk.shape,  y_test_tkk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод: все твиты имеют отношение хотя бы к одной из компаний\n",
    "# Вывод: есть твиты, которые имеют отношение к нескольким компаниям!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfabank</th>\n",
       "      <th>bankmoskvy</th>\n",
       "      <th>gazprom</th>\n",
       "      <th>raiffeisen</th>\n",
       "      <th>rshb</th>\n",
       "      <th>sberbank</th>\n",
       "      <th>uralsib</th>\n",
       "      <th>vtb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3162</td>\n",
       "      <td>3275</td>\n",
       "      <td>3194</td>\n",
       "      <td>3001</td>\n",
       "      <td>3093</td>\n",
       "      <td>1449</td>\n",
       "      <td>3304</td>\n",
       "      <td>3068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alfabank bankmoskvy gazprom raiffeisen  rshb sberbank uralsib   vtb\n",
       "count      3313       3313    3313       3313  3313     3313    3313  3313\n",
       "unique        4          4       4          4     4        4       3     4\n",
       "top        NULL       NULL    NULL       NULL  NULL        0    NULL  NULL\n",
       "freq       3162       3275    3194       3001  3093     1449    3304  3068"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_banks.describe()\n",
    "# У компаний м/б только значения \"NULL\", 0, -1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>NULL</th>\n",
       "      <th>NotNULL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alfabank</th>\n",
       "      <td>59.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankmoskvy</th>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gazprom</th>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3194.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raiffeisen</th>\n",
       "      <td>16.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rshb</th>\n",
       "      <td>4.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sberbank</th>\n",
       "      <td>645.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>2324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uralsib</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3304.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vtb</th>\n",
       "      <td>45.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               -1       0      1    NULL  NotNULL\n",
       "alfabank     59.0    77.0   15.0  3162.0    151.0\n",
       "bankmoskvy   10.0    23.0    5.0  3275.0     38.0\n",
       "gazprom       4.0   110.0    5.0  3194.0    119.0\n",
       "raiffeisen   16.0   284.0   12.0  3001.0    312.0\n",
       "rshb          4.0   199.0   17.0  3093.0    220.0\n",
       "sberbank    645.0  1449.0  230.0   989.0   2324.0\n",
       "uralsib       1.0     8.0    NaN  3304.0      9.0\n",
       "vtb          45.0   166.0   34.0  3068.0    245.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Еще немного статистики\n",
    "a = []\n",
    "for column in y_test_banks.columns:\n",
    "    a.append(y_test_banks[column].value_counts())\n",
    "stat = pd.DataFrame(a)\n",
    "stat[\"NotNULL\"] = np.sum(stat, 1) - stat[\"NULL\"]\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>NULL</th>\n",
       "      <th>NotNULL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alfabank</th>\n",
       "      <td>59.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankmoskvy</th>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gazprom</th>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3194.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raiffeisen</th>\n",
       "      <td>16.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rshb</th>\n",
       "      <td>4.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sberbank</th>\n",
       "      <td>645.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>2324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uralsib</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3304.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vtb</th>\n",
       "      <td>45.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               -1       0      1    NULL  NotNULL\n",
       "alfabank     59.0    77.0   15.0  3162.0    151.0\n",
       "bankmoskvy   10.0    23.0    5.0  3275.0     38.0\n",
       "gazprom       4.0   110.0    5.0  3194.0    119.0\n",
       "raiffeisen   16.0   284.0   12.0  3001.0    312.0\n",
       "rshb          4.0   199.0   17.0  3093.0    220.0\n",
       "sberbank    645.0  1449.0  230.0   989.0   2324.0\n",
       "uralsib       1.0     8.0    NaN  3304.0      9.0\n",
       "vtb          45.0   166.0   34.0  3068.0    245.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Еще немного статистики\n",
    "a = []\n",
    "for column in y_test_banks.columns:\n",
    "    a.append(y_test_banks[column].value_counts())\n",
    "stat = pd.DataFrame(a)\n",
    "stat[\"NotNULL\"] = np.sum(stat, 1) - stat[\"NULL\"]\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы упростить задачу будем \"наивно\" относить каждый твит только к одному сентименту\n",
    "\n",
    "def naivelabeling(df):\n",
    "    y_naive = np.array([0] * df.shape[0])\n",
    "    distr = np.array(np.matrix([np.sum(df == \"0\", 1), np.sum(df == \"-1\", 1), np.sum(df == \"1\", 1)]).T)\n",
    "    for itr, comb in enumerate(distr):\n",
    "        if comb[0] >= comb[1] and comb[0] >= comb[2]:\n",
    "            y_naive[itr] = 0\n",
    "        elif comb[1] >= comb[2]:\n",
    "            y_naive[itr] = -1\n",
    "        else:\n",
    "            y_naive[itr] = 1\n",
    "    return y_naive\n",
    "\n",
    "y_train_banks_naive = naivelabeling(y_train_banks)\n",
    "y_test_banks_naive = naivelabeling(y_test_banks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В роли бейзлайна возьмем на каждом объекте самый популярный в выборке ответ,\n",
    "# то есть -1 для обеих выборок\n",
    "\n",
    "y_predict_tkk = np.array([-1] * X_test_tkk.shape[0])\n",
    "y_predict_banks = np.array([-1] * X_test_banks.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35111719106247147"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f-мера для такого бейзлайна, если считать наивные верные ответы за истинные\n",
    "metrics.f1_score(y_test_banks_naive, y_predict_banks, labels = [-1, 1], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функцию, которая будет считать f-меру для ВСЕХ упоминаний компаний в твитах\n",
    "def f_measure(y_true, prediction):\n",
    "    \"\"\"y_true - pd.DataFrame (NxM),\n",
    "    prediction - np.array(N,)\n",
    "    \n",
    "    returns (macro f1-score, micro f1-score)\"\"\"\n",
    "    \n",
    "    fill_value = pd.DataFrame({col: prediction for col in y_true.columns})\n",
    "    prediction = y_true[y_true == \"NULL\"].fillna(fill_value, axis = 1)\n",
    "    y_true = [int(x) for x in y_true.values.flatten() if x != \"NULL\"]\n",
    "    prediction = [int(x) for x in prediction.values.flatten() if x != \"NULL\"]\n",
    "    f_macro = metrics.f1_score(y_true, prediction, labels = [-1, 1], average=\"macro\")\n",
    "    f_micro = metrics.f1_score(y_true, prediction, labels = [-1, 1], average=\"micro\")\n",
    "    return f_macro, f_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения полной f-меры для ТКК и банков:\n",
      "(0.3217535153019024, 0.6049766718506999) (0.1865778200856735, 0.34690265486725663)\n",
      "\n",
      "Любопытства ради посмотрим, насколько наивное предсказание отличается \n",
      "от истинного, по сути - это лучший результат, который можно получить:\n",
      "(0.9383921593645832, 0.9677419354838709) (0.9888615964842706, 0.9909173478655767)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasinkd/venv/python3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Значения полной f-меры для ТКК и банков:\")\n",
    "print(f_measure(y_test_tkk, y_predict_tkk), f_measure(y_test_banks, y_predict_banks))\n",
    "print(\"\\nЛюбопытства ради посмотрим, насколько наивное предсказание отличается \\n\\\n",
    "от истинного, по сути - это лучший результат, который можно получить:\")\n",
    "print(f_measure(y_test_tkk, naivelabeling(y_test_tkk)), f_measure(y_test_banks, y_test_banks_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Будем работать с выборкой по банкам, т.к. в ней почти нет пересекающихся сентиментов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Эта функция считает твит положительным или отрицательным, если в нем есть хотя бы\n",
    "# один положительный или отрицательный сентимент\n",
    "\n",
    "# Именно такой подход использовали организаторы соревнования\n",
    "\n",
    "def f_measure2(y_true, prediction):\n",
    "    \"\"\"y_true - pd.DataFrame (NxM),\n",
    "    prediction - np.array(N,)\n",
    "    \n",
    "    returns (macro f1-score, micro f1-score)\"\"\"\n",
    "    \n",
    "    positive_tweets_true = np.sum(y_true == \"1\", 1) > 0\n",
    "    positive_tweets_prediction = prediction == 1\n",
    "    \n",
    "    negative_tweets_true = np.sum(y_true == \"-1\", 1) > 0\n",
    "    negative_tweets_prediction = prediction == -1\n",
    "    \n",
    "    TN_pos, FP_pos, FN_pos, TP_pos = metrics.confusion_matrix(positive_tweets_true, \n",
    "                                                              positive_tweets_prediction).flatten()\n",
    "    TN_neg, FP_neg, FN_neg, TP_neg = metrics.confusion_matrix(negative_tweets_true, \n",
    "                                                              negative_tweets_prediction).flatten()\n",
    "    \n",
    "    micro_precision = (TP_pos + TP_neg)/(TP_pos + TP_neg + FP_pos + FP_neg)\n",
    "    micro_recall = (TP_pos + TP_neg)/(TP_pos + TP_neg + FN_pos + FN_neg)\n",
    "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
    "    \n",
    "    precision_pos = np.nan_to_num((TP_pos)/(TP_pos + FP_pos))\n",
    "    precision_neg = np.nan_to_num((TP_neg)/(TP_neg + FP_neg))\n",
    "    macro_precision = (precision_pos + precision_neg)/2\n",
    "    \n",
    "    recall_pos = np.nan_to_num((TP_pos)/(TP_pos + FN_pos))\n",
    "    recall_neg = np.nan_to_num((TP_neg)/(TP_neg + FN_neg))\n",
    "    macro_recall = (recall_pos + recall_neg)/2\n",
    "    \n",
    "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision+macro_recall)\n",
    "    \n",
    "    return macro_f1, micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения данной f-меры для ТКК и банков:\n",
      "(0.3192971826719176, 0.5976750779699461) (0.18898408812729497, 0.35114851034796457)\n",
      "\n",
      "Любопытства ради посмотрим, насколько наивное предсказание отличается \n",
      "от истинного, по сути - это лучший результат, который можно получить:\n",
      "(0.9506662848835928, 0.980891719745223) (0.9920785367262137, 0.9949003245248029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasinkd/venv/python3.5/lib/python3.5/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "print(\"Значения данной f-меры для ТКК и банков:\")\n",
    "print(f_measure2(y_test_tkk, y_predict_tkk), f_measure2(y_test_banks, y_predict_banks))\n",
    "print(\"\\nЛюбопытства ради посмотрим, насколько наивное предсказание отличается \\n\\\n",
    "от истинного, по сути - это лучший результат, который можно получить:\")\n",
    "print(f_measure2(y_test_tkk, naivelabeling(y_test_tkk)), f_measure2(y_test_banks, y_test_banks_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_prob(x):\n",
    "    # убираем твиттеровское форматирование\n",
    "    x = re.sub(\"&[^;]*;[^;]*;\", '', x)\n",
    "    x = re.sub(\"&[^;]*;\", '', x)\n",
    "    # Если пробелов больше одного - оставляем один\n",
    "    x = re.sub('[\\s]+', ' ', x)\n",
    "    return x\n",
    "\n",
    "def normal(x):\n",
    "    # приводим все к строчному виду\n",
    "    x = x.lower()\n",
    "    # убираем все ссылки\n",
    "    x = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',x)\n",
    "    # Убираем все упоминания пользователей\n",
    "    x = re.sub('@[^\\s]+','',x)\n",
    "    # убираем хэштеги\n",
    "    x = re.sub('#', '', x)\n",
    "    # Убираем все, что начинается с цифр\n",
    "    x = re.sub(\" \\d[^\\s]*\", '', x)\n",
    "    x = re.sub(\"\\d+\", '', x)\n",
    "    # Если символ встречается больше 2 раз подряд, то заменяем 1 символом\n",
    "    x = re.sub(r\"(.)\\1{2,}\", r'\\1', x)\n",
    "    # Убираем всю пунктуацию \n",
    "    x = re.sub(\"[^\\w']\", \" \", x)\n",
    "    # Убираем, что осталось от твиттерского форматирования:\n",
    "    x = re.sub(\"(?:^|\\W)rt(?:$|\\W)\", \"\", x)\n",
    "    x = re.sub(\"(?:^|\\W)r(?:$|\\W)\", \"\", x)\n",
    "    x = re.sub(\"(?:^|\\W)г(?:$|\\W)\", \"\", x)\n",
    "    # Если пробелов больше одного - оставляем один\n",
    "    x = re.sub('[\\s]+', ' ', x)\n",
    "    # убираем пробелы в начале и в конце\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "X_train_banks = [parsing_prob(x) for x in X_train_banks]\n",
    "X_test_banks = [parsing_prob(x) for x in X_test_banks]\n",
    "\n",
    "X_train_banks_pr = [normal(x) for x in X_train_banks]\n",
    "X_test_banks_pr = [normal(x) for x in X_test_banks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В лемматизации нет объединения не со следующим словом!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmat(txt):\n",
    "    corrector = jamspell.TSpellCorrector()\n",
    "    corrector.LoadLangModel('ru_small.bin')\n",
    "    mystem = Mystem()\n",
    "    s0 = \"\"\n",
    "    for s in tqdm(txt):\n",
    "        s = corrector.FixFragment(s)\n",
    "        s0 = s0 + \" ?&$ \" + s\n",
    "    \n",
    "    lem_list = ''.join(mystem.lemmatize(s0))\n",
    "\n",
    "    return lem_list.split(\" ?&$ \")[1:]\n",
    "\n",
    "# pool = Pool()\n",
    "\n",
    "# X_train_banks_lm, X_test_banks_lm, X_train_banks_pr_lm, X_test_banks_pr_lm = \\\n",
    "# pool.map(lemmat, [X_train_banks, X_test_banks, X_train_banks_pr, X_test_banks_pr])\n",
    "     \n",
    "# pd.DataFrame(X_train_banks_lm).to_csv(\"X_train_banks_lm.txt\", index = False)\n",
    "# pd.DataFrame(X_test_banks_lm).to_csv(\"X_test_banks_lm.txt\", index = False)\n",
    "# pd.DataFrame(X_train_banks_pr_lm).to_csv(\"X_train_banks_pr_lm.txt\", index = False)\n",
    "# pd.DataFrame(X_test_banks_pr_lm).to_csv(\"X_test_banks_pr_lm.txt\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_banks_lm = [item for sublist in pd.read_csv(\"Corpuses/SentiRuEval/X_test_banks_lm.txt\").values for item in sublist]\n",
    "X_train_banks_lm = [item for sublist in pd.read_csv(\"Corpuses/SentiRuEval/X_train_banks_lm.txt\").values for item in sublist]\n",
    "X_train_banks_pr_lm = [item for sublist in pd.read_csv(\"Corpuses/SentiRuEval/X_train_banks_pr_lm.txt\").values for item in sublist]\n",
    "X_test_banks_pr_lm = [item for sublist in pd.read_csv(\"Corpuses/SentiRuEval/X_test_banks_pr_lm.txt\").values for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9392, 9392, 9392, 3313, 3313, 3313)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_banks_lm), len(X_train_banks_pr_lm), len(X_train_banks), len(X_test_banks_lm), len(X_test_banks_pr_lm), len(X_test_banks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-18:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-23:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-24:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Авторские стоп-слова.\n",
    "\n",
    "extractor = LocationExtractor()\n",
    "\n",
    "def extract_loc(text):\n",
    "    matches = extractor.parser.extract(text)\n",
    "    return [match.fact.name for match in matches]\n",
    "\n",
    "pool = Pool()\n",
    "res = pool.map(extract_loc, X_train_banks_pr_lm + X_test_banks_pr_lm)\n",
    "\n",
    "organisations = Counter()\n",
    "for matches in res:\n",
    "    for match in matches:\n",
    "        organisations[match] += 1\n",
    "        \n",
    "locations = [x[0] for x in organisations.most_common() if x[1]>1]\n",
    "\n",
    "bank_names = [\"альфа\", \"альфабанк\", \"альфа банк\", \"альфабанка\", \"банк москвы\", \"банк москва\", \"рсхб\", \"россельхозбанк\", \"россельхоз банк\", \"банк\", \"банка\", \"втб\", \"райффайзенбанк\",  \"райфайзенбанк\",  \"райффайзен банк\", \"райффайзен\", \"райфайзен\", \"сбербанк\", \"сбер\", \"газпром\", \"газпромбанк\", \"северо\", \"запад\", \"уралсиб\", 'открытый акционерный общество', \"филиал\", \"sberbank\", \"cib\"]\n",
    "\n",
    "author_stop_words = locations + bank_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Классические стоп-слова\n",
    "with open(\"stop_words.txt\", \"r\", encoding=\"cp1251\") as fout:\n",
    "        stop_words = fout.read().split(\" ?&$ \")[:-1]\n",
    "stop_words.pop(stop_words.index(\"не\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Features (check stability effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA будем строить с помощью библиотеки gensim.\n",
    "В качестве слов, которые будут отброшены из словаря были взяты стоп-слова для русского языка из NLTK, а также названия банков, т.к. они не несут в себе информацию о теме документа.\n",
    "\n",
    "Так же была идея отбросить слишком часто встречающиеся слова, но при таком подходе из словаря были убраны слова, очень важные для определения темы, например \"санкция\", которое встречается в обучающей коллекции 700 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda_texts = [x.split() for x in X_train_banks_pr_lm]\n",
    "X_test_lda_texts = [x.split() for x in X_test_banks_pr_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 1/30 [00:18<08:43, 18.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 2/30 [00:36<08:32, 18.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 3/30 [00:56<08:30, 18.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 4/30 [01:16<08:20, 19.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 5/30 [01:37<08:05, 19.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 6/30 [01:58<07:52, 19.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 7/30 [02:18<07:34, 19.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 8/30 [02:38<07:16, 19.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 9/30 [02:59<06:57, 19.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 10/30 [03:20<06:40, 20.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 11/30 [03:40<06:20, 20.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 12/30 [04:00<06:00, 20.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 13/30 [04:20<05:40, 20.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 14/30 [04:40<05:20, 20.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 15/30 [05:00<05:00, 20.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 16/30 [05:20<04:40, 20.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 17/30 [05:40<04:20, 20.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 18/30 [06:00<04:00, 20.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 19/30 [06:20<03:40, 20.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 20/30 [06:42<03:21, 20.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 21/30 [07:02<03:01, 20.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 22/30 [07:22<02:41, 20.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 23/30 [07:43<02:21, 20.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 24/30 [08:03<02:00, 20.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 25/30 [08:24<01:40, 20.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 26/30 [08:44<01:20, 20.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 27/30 [09:05<01:00, 20.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 28/30 [09:25<00:40, 20.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 29/30 [09:45<00:20, 20.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 30/30 [10:06<00:00, 20.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(30)):\n",
    "    X_train_lda, X_test_lda, y_train_lda, y_test_lda = train_test_split(X_train_banks_pr_lm, y_train_banks_naive, test_size = 0.15, stratify=y_train_banks_naive)\n",
    "\n",
    "    # Подготовка\n",
    "    X_train_lda_dictionary = corpora.Dictionary(X_train_lda_texts) \n",
    "\n",
    "    # Исключение из словаря слов, которые не несут в себе информацию о теме документа\n",
    "    bad_ids = [X_train_lda_dictionary.token2id[x] for x in author_stop_words + stop_words if x in X_train_lda_dictionary.token2id]\n",
    "\n",
    "    X_train_lda_dictionary.filter_tokens(bad_ids=bad_ids)\n",
    "    X_train_lda_dictionary.filter_extremes(no_below = 2, no_above = .5)\n",
    "    X_train_lda_dictionary.filter_n_most_frequent(50)\n",
    "\n",
    "    lda_train_corpus = [X_train_lda_dictionary.doc2bow(text.split()) for text in X_train_lda]\n",
    "    lda_test_corpus = [X_train_lda_dictionary.doc2bow(text.split()) for text in X_test_lda]\n",
    "\n",
    "    # Обучение\n",
    "\n",
    "    ldamodel = models.ldamulticore.LdaMulticore(lda_train_corpus, alpha = 0.0001, \n",
    "                                                eta = 'auto', id2word=X_train_lda_dictionary, \n",
    "                                                num_topics=num, passes=10, workers=7)\n",
    "    lda_train_features = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                           in list(lda_train_corpus)]).applymap(lambda x: round(x[1], 2))\n",
    "\n",
    "    lda_test_features = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                           in list(lda_test_corpus)]).applymap(lambda x: round(x[1], 2))\n",
    "\n",
    "    estimator = RandomForestClassifier(n_estimators=200, n_jobs=7)\n",
    "    estimator.fit(lda_train_features, y_train_lda)\n",
    "    y_predict = estimator.predict(lda_test_features)\n",
    "    score = {}\n",
    "    score[\"test\"] = metrics.f1_score(y_test_lda, y_predict, average='macro')\n",
    "    score[\"perplexity\"] = ldamodel.log_perplexity(lda_test_corpus)\n",
    "    coherence_model_lda = CoherenceModel(model=ldamodel, texts=[text.split() for text in X_train_lda], dictionary=X_train_lda_dictionary, coherence='c_v')\n",
    "    score[\"coherence\"] = coherence_model_lda.get_coherence()    \n",
    "\n",
    "    # print(\"Test macro f1 score: {}\".format(metrics.f1_score(y_test_lda, y_predict, average='macro')))\n",
    "\n",
    "    ldamodel.update(lda_test_corpus)\n",
    "\n",
    "    X_train_banks_lda = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                               in list(X_train_lda_corpus)]).applymap(lambda x: round(x[1], 2))\n",
    "    X_test_banks_lda = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                           in list(X_test_lda_corpus)]).applymap(lambda x: round(x[1], 2))\n",
    "\n",
    "    estimator = RandomForestClassifier(n_estimators=200, n_jobs=7)\n",
    "    estimator.fit(X_train_banks_lda, y_train_banks_naive)\n",
    "    y_predict = estimator.predict(X_test_banks_lda)\n",
    "    score[\"validation\"] = f_measure2(y_test_banks, y_predict)[0]\n",
    "    scores.append(score)\n",
    "    # print(\"Validation macro f1 score: %s\" % f_measure2(y_test_banks, y_predict)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'coherence': 0.6286252759760068,\n",
       "  'perplexity': -12.166463824147998,\n",
       "  'test': 0.3871540446771635,\n",
       "  'validation': 0.244884193707033},\n",
       " {'coherence': 0.6362521623114114,\n",
       "  'perplexity': -12.107560286562965,\n",
       "  'test': 0.3926451584642005,\n",
       "  'validation': 0.1973052016493977},\n",
       " {'coherence': 0.6566827680639061,\n",
       "  'perplexity': -12.013797314752901,\n",
       "  'test': 0.37819806208422296,\n",
       "  'validation': 0.19098044321853166},\n",
       " {'coherence': 0.6422531549268456,\n",
       "  'perplexity': -12.13878293301816,\n",
       "  'test': 0.38425194691971476,\n",
       "  'validation': 0.18733773174676518},\n",
       " {'coherence': 0.6432010258708332,\n",
       "  'perplexity': -12.104618313644671,\n",
       "  'test': 0.40310796055892717,\n",
       "  'validation': 0.18430933286018628},\n",
       " {'coherence': 0.638256213235123,\n",
       "  'perplexity': -12.142647157348327,\n",
       "  'test': 0.39627049387987207,\n",
       "  'validation': 0.1839320125852185},\n",
       " {'coherence': 0.6268224925260641,\n",
       "  'perplexity': -12.316735255930334,\n",
       "  'test': 0.3664090627950129,\n",
       "  'validation': 0.1817408722595824},\n",
       " {'coherence': 0.6572189900525227,\n",
       "  'perplexity': -11.928471200217402,\n",
       "  'test': 0.3835606144793171,\n",
       "  'validation': 0.18153323756040227},\n",
       " {'coherence': 0.6295010291914827,\n",
       "  'perplexity': -11.950623734325482,\n",
       "  'test': 0.377226660400213,\n",
       "  'validation': 0.1800530218655159},\n",
       " {'coherence': 0.6272551575319606,\n",
       "  'perplexity': -11.990406352876377,\n",
       "  'test': 0.3847485063848133,\n",
       "  'validation': 0.17940204242176405},\n",
       " {'coherence': 0.6263254269497711,\n",
       "  'perplexity': -12.109489100179564,\n",
       "  'test': 0.3587596762735889,\n",
       "  'validation': 0.17709014711571044},\n",
       " {'coherence': 0.6268051947012143,\n",
       "  'perplexity': -12.152794669336254,\n",
       "  'test': 0.38666104964447506,\n",
       "  'validation': 0.17486270617391414},\n",
       " {'coherence': 0.6426580211559291,\n",
       "  'perplexity': -11.946292427831102,\n",
       "  'test': 0.3730877317200403,\n",
       "  'validation': 0.17369978151159976},\n",
       " {'coherence': 0.6258609772690449,\n",
       "  'perplexity': -12.184309206855582,\n",
       "  'test': 0.40115835781858306,\n",
       "  'validation': 0.16996866329299415},\n",
       " {'coherence': 0.6328844281160092,\n",
       "  'perplexity': -11.951954799511011,\n",
       "  'test': 0.34611733636600533,\n",
       "  'validation': 0.1691249514413659},\n",
       " {'coherence': 0.6427856571922371,\n",
       "  'perplexity': -12.157021203983263,\n",
       "  'test': 0.3580610123203922,\n",
       "  'validation': 0.16820647554613954},\n",
       " {'coherence': 0.643258993678778,\n",
       "  'perplexity': -12.143652421998064,\n",
       "  'test': 0.36558931044773074,\n",
       "  'validation': 0.16658969014526118},\n",
       " {'coherence': 0.6528355149572767,\n",
       "  'perplexity': -11.88744282682867,\n",
       "  'test': 0.37105973698357203,\n",
       "  'validation': 0.16619966666072847},\n",
       " {'coherence': 0.6431522547897204,\n",
       "  'perplexity': -11.96821301569739,\n",
       "  'test': 0.4093768328643903,\n",
       "  'validation': 0.1644861993122126},\n",
       " {'coherence': 0.6436112702624909,\n",
       "  'perplexity': -11.955617193196362,\n",
       "  'test': 0.3572102234212507,\n",
       "  'validation': 0.1643283358646203},\n",
       " {'coherence': 0.6251072739415882,\n",
       "  'perplexity': -12.030188341097112,\n",
       "  'test': 0.38860828717268253,\n",
       "  'validation': 0.16170826640750277},\n",
       " {'coherence': 0.6275529014520691,\n",
       "  'perplexity': -12.015790816516764,\n",
       "  'test': 0.39870344277046255,\n",
       "  'validation': 0.16162086466872908},\n",
       " {'coherence': 0.6394340084782383,\n",
       "  'perplexity': -11.889045505291287,\n",
       "  'test': 0.38558836670397034,\n",
       "  'validation': 0.16010840959132985},\n",
       " {'coherence': 0.641639076074109,\n",
       "  'perplexity': -12.178242520212374,\n",
       "  'test': 0.389734127820043,\n",
       "  'validation': 0.15407176438170078},\n",
       " {'coherence': 0.6397883054495068,\n",
       "  'perplexity': -12.111788169139647,\n",
       "  'test': 0.40915771256525457,\n",
       "  'validation': 0.1505636133414417},\n",
       " {'coherence': 0.6204564507241759,\n",
       "  'perplexity': -12.023066233840106,\n",
       "  'test': 0.3995683542162718,\n",
       "  'validation': 0.1501715377972222},\n",
       " {'coherence': 0.6415125053411312,\n",
       "  'perplexity': -12.083354181691863,\n",
       "  'test': 0.36485325072674174,\n",
       "  'validation': 0.14865210836677104},\n",
       " {'coherence': 0.6373283787773814,\n",
       "  'perplexity': -12.066851497329948,\n",
       "  'test': 0.36813627517438935,\n",
       "  'validation': 0.1444749010605199},\n",
       " {'coherence': 0.6539026256904685,\n",
       "  'perplexity': -12.077486576873202,\n",
       "  'test': 0.38849648043056545,\n",
       "  'validation': 0.14432361143556607},\n",
       " {'coherence': 0.6483931737898265,\n",
       "  'perplexity': -11.987185878381968,\n",
       "  'test': 0.386187514546918,\n",
       "  'validation': 0.14412936031101306}]"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = sorted(scores, key = lambda x: x[\"validation\"], reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = scale([x[\"test\"] for x in scores])\n",
    "validation_scores = scale([x[\"validation\"] for x in scores])\n",
    "perplexity_scores = scale([x[\"perplexity\"] for x in scores])\n",
    "coherence_scores = scale([x[\"coherence\"] for x in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(validation_scores)), validation_scores, label=\"Validation F1 Score\")\n",
    "plt.plot(range(len(validation_scores)), test_scores, label=\"Test F1 Score\")\n",
    "plt.plot(range(len(validation_scores)), coherence_scores, label=\"Coherence\")\n",
    "plt.plot(range(len(validation_scores)), perplexity_scores, label=\"Perplexity\")\n",
    "plt.legend()\n",
    "plt.title(\"Standardized metrics of LDA quality\\n(perplexity and coherence) and\\n standardized metrics of sentiment prediction quality\\nbased on features from LDA\")\n",
    "plt.xlabel(\"# of model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.015821930833737296, 0.9338650836916045),\n",
       " (-0.23207320075095217, 0.21718869001101535),\n",
       " (-0.14645321009806736, 0.43996621994132623))"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(test_scores, validation_scores), pearsonr(perplexity_scores, validation_scores), pearsonr(coherence_scores, validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ качество модели на валидационной выборке, построенной на базе признаков, полученных с помоью LDA, не зависит ни от качества модели на тестовой выборке, ни от внутренних критериев качества моделей LDA.\n",
    "\n",
    "__Выдвигаем следующую гипотезу:__ качество моделей, построенных на большем количестве признаков, среди которых есть признаки, полученные с помощью LDA, в незначительной степени зависит от инициализации моделей LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка\n",
    "lda_stop_words = author_stop_words + stop_words #+ [\"не\"]#+ [\"кредит\", \"ипотечный\", \"бизнес\", \"млрд\", \"рубль\"]\n",
    "\n",
    "X_train_lda_texts = [[word for word in x.split() if word not in lda_stop_words] for x in X_train_banks_pr_lm]\n",
    "# X_train_lda_texts = [[\" \".join(x) for x in ngrams(doc, 2)] + doc for doc in X_train_lda_texts0]\n",
    "X_train_lda_dictionary = corpora.Dictionary(X_train_lda_texts) \n",
    "X_train_lda_corpus = [X_train_lda_dictionary.doc2bow(text) for text in X_train_lda_texts]\n",
    "\n",
    "# Исключение из словаря слов, которые не несут в себе информацию о теме документа\n",
    "stop_words_ids = [X_train_lda_dictionary.token2id[x] for x in [\"не\"] if x in list(X_train_lda_dictionary.values())]\n",
    "banks_ids = [X_train_lda_dictionary.token2id[x] for x in stop_words if x in X_train_lda_dictionary.token2id]\n",
    "\n",
    "bad_ids = stop_words_ids + banks_ids\n",
    "# bad_ids = [key for key in X_train_lda_dictionary.dfs.keys() if X_train_lda_dictionary.dfs[key] > 700]# + banks_ids\n",
    "\n",
    "# X_train_lda_dictionary.filter_tokens(bad_ids=bad_ids)\n",
    "X_train_lda_dictionary.filter_extremes(no_below = 2, no_above = .5)\n",
    "X_train_lda_dictionary.filter_n_most_frequent(50)\n",
    "X_train_lda_corpus = [X_train_lda_dictionary.doc2bow(text) for text in X_train_lda_texts]\n",
    "\n",
    "X_test_lda_texts = [x.split() for x in X_test_banks_pr_lm]\n",
    "\n",
    "X_test_lda_texts = [[word for word in x.split() if word not in lda_stop_words] for x in X_test_banks_pr_lm]\n",
    "# X_test_lda_texts = [[\" \".join(x) for x in ngrams(doc, 2)] + doc for doc in X_test_lda_texts0]\n",
    "\n",
    "X_test_lda_corpus = [X_train_lda_dictionary.doc2bow(text) for text in X_test_lda_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были построены модели, выделяющие 5, 10 и 20 тем.  \n",
    "В качестве параметра alpha, характеризующего степень разреженность матрицы темы-документы было выбрано значение 0.0001, т. к. особенности Твиттера подразумевают, что одно пользовательское сообщение должно содержать в себе одну тему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [5, 10, 20]\n",
    "num_topics = [10]\n",
    "\n",
    "X_train_banks_lda = {} \n",
    "X_test_banks_lda = {} \n",
    "\n",
    "for num in num_topics:\n",
    "    ldamodel = models.ldamulticore.LdaMulticore(X_train_lda_corpus, alpha = 0.0001, \n",
    "                                                eta = 'auto', id2word=X_train_lda_dictionary, \n",
    "                                                num_topics=num, passes=10)\n",
    "    X_train_banks_lda[num] = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                           in list(X_train_lda_corpus)]).applymap(lambda x: round(x[1], 2))\n",
    "#     ldamodel.   update(X_test_lda_corpus)\n",
    "    X_test_banks_lda[num] = pd.DataFrame([ldamodel.get_document_topics(x,  minimum_probability=0) for x \\\n",
    "                                           in list(X_test_lda_corpus)]).applymap(lambda x: round(x[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saveLDAtofiles(txt, name, num_topics):\n",
    "#     for num in num_topics:\n",
    "#         txt[num].to_csv(\"Corpuses/SentiRuEval/\"+name+str(num)+\".csv\", sep = \";\", index = False)\n",
    "# saveLDAtofiles(X_train_banks_lda, \"X_train_banks_lda\", num_topics)\n",
    "# saveLDAtofiles(X_test_banks_lda, \"X_test_banks_lda\", num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLDAfiles(name, num_topics):\n",
    "    test = {}\n",
    "    for num in num_topics:\n",
    "        test[num] = pd.read_csv('Corpuses/SentiRuEval/'+name+str(num)+\".csv\", sep = \";\")\n",
    "        test[num].columns = list(map(lambda x: 'lda_topic_'+ str(x), list(range(1, num+1))))\n",
    "    return test\n",
    "\n",
    "X_test_banks_lda = readLDAfiles(\"X_test_banks_lda\", num_topics)\n",
    "X_train_banks_lda = readLDAfiles(\"X_train_banks_lda\", num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_banks_lda[20].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_cols = [\"word\", \"POS\", \"lemma\", \"sentiment\", \"source\", \"ambiguity\"]\n",
    "# val_dict = pd.read_table(\"rusentilex_2017.txt\", sep = \",\", names = my_cols, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь был очищен от ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dict.loc[val_dict[val_dict.sentiment.isin(['posiive', 'posititve', \n",
    "#                                                'postitive', \"postive\"])].index, \"sentiment\"] = \"positive\"\n",
    "# val_dict.loc[val_dict[val_dict.sentiment.isin(['negative ', 'negaitve'])].index, \"sentiment\"] = \"negative\"\n",
    "\n",
    "# val_dict.loc[val_dict[val_dict.source.isin(['opinion ', 'opinion  ', 'opinon', 'opinegativenion',\n",
    "#                                             'opinion    ', 'opinion                     '])].index, \"source\"] = \"opinion\"\n",
    "# val_dict.loc[val_dict[val_dict.source.isin(['fact ', 'fact В ТЕЗ EMPTY',\n",
    "#                                            'fact В ТЕЗ empty', 'factg'])].index, \"source\"] = \"fact\"\n",
    "# val_dict.loc[val_dict[val_dict.source.isin(['feeling ', 'feeling  ',\n",
    "#                                            'feeeling'])].index, \"source\"] = \"feeling\"\n",
    "# val_dict.loc[val_dict[val_dict.source.isin(['operator '])].index, \"source\"] = 'operator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dict.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dict.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждой тональности сопоставлена бинарная переменная. Также каждому слову/словосочетанию сопоставлены бинарные переменные, отвечающие за эмоциональное или неэмоциональное происхождение слова.  \n",
    "Параметры для многозначных слов были усреднены. Таким образом, для каждого слова в словаре сумма по строке столбцов, отвечающих за тональность = 1, так же как и сумма столбцов, отвечающих за происхождение слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = pd.get_dummies(val_dict[[\"lemma\", \"sentiment\", \"source\"]], columns=[\"sentiment\", \"source\"])\n",
    "# grouped[\"emotional\"] = grouped[[\"source_feeling\", \"source_opinion\"]].sum(axis=1)\n",
    "# grouped[\"not_emotional\"] = grouped[[\"source_fact\", \"source_operator\"]].sum(axis=1)\n",
    "# grouped.drop([\"source_feeling\", \"source_opinion\", \"source_fact\", \"source_operator\"], axis = 1, inplace=True)\n",
    "\n",
    "# grouped = grouped.groupby(\"lemma\", as_index=False).mean()\n",
    "# grouped[\"lemma\"] = grouped.lemma.apply(lambda x: x.lower().split(\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Части слов в словаре было сопоставленно несколько его лемматизированных форм, поэтому для каждой из этих форм были продумлированы показатели, вычисленные для порождающего эту лемму слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def separate_lemmas(grouped):\n",
    "#     valence_df = pd.DataFrame(columns=grouped.columns)\n",
    "#     for i in tqdm(range(grouped.shape[0])):\n",
    "#         df = pd.DataFrame(columns=grouped.columns)\n",
    "#         a = grouped.iloc[i,0]\n",
    "#         b = grouped.iloc[i, 1:]\n",
    "#         df.lemma = a\n",
    "#         for el in range(len(a)):\n",
    "#             df.iloc[el, 1:] = b\n",
    "#         valence_df = pd.concat([valence_df, df])\n",
    "#     return valence_df\n",
    "    \n",
    "# grouped = separate_lemmas(grouped=grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было вычислено чило слов в каждой лемме, леммы с числом слов больше 3 были удалены из словаря, т.к. таких словосочетаний в словаре очень мало (около 1%), но их учет значительно увеличивает время работы алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped[\"words_count\"] = list(map(lambda x: len(x.split()), grouped.lemma.values))\n",
    "# sum(grouped['words_count'] > 3)/grouped.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = grouped[grouped['words_count'] <= 3].reset_index().drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped.to_csv(\"valence_df.csv\", index=False)\n",
    "# grouped = pd.read_csv(\"valence_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из словаря тональности был создан словарь, где каждой лемме был сопоставлен ее номер в датафрейме grouped. Предложения, для которых нужно оценить тональность, векторизуются с помощью CountVectorizer c ключами из словаря тональности. Получилась очень разреженная матрица. Из нее с помощью np.nonzero получаем набор индексов, где первый набор - номер предложения, а второй - номер слова из словаря тональности, которое присутствует в данном предложении. Каждому предложению сопостовляем 6 параметров: 'sentiment_negative', 'sentiment_neutral', 'sentiment_positive',                                                           'sentiment_positive/negative', 'emotional', 'not_emotional'. Если в предложении нет слов из словаря, то значения для него равны нулю по каждому из шести столбцов. Если же слова/словосочетания есть, то значения из словаря тональности каждого слова/словосочетания из предложения прибавляются взвешенные на отношение длины слова/словосочетания на длину предложения.  \n",
    "\n",
    "Ключ отвечает за отображение самых популярных слов в датасете среди присутствующих в словаре тональности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev_my_vocab = grouped[\"lemma\"].to_dict()\n",
    "# my_vocab = {v : k for k, v in rev_my_vocab.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valence_dataset(data, verbose=False):\n",
    "#     vectorizer = CountVectorizer(ngram_range=(1,3), vocabulary=my_vocab)\n",
    "#     vectorized_list = vectorizer.fit_transform(data)\n",
    "#     contain_valence = np.nonzero(vectorized_list)\n",
    "#     map_sent_valence = list(zip(contain_valence[0], list(contain_valence[1])))\n",
    "#     result = pd.DataFrame(np.zeros((len(data), 6)), columns = ['sentiment_negative', 'sentiment_neutral', 'sentiment_positive', \\\n",
    "#                                                                    'sentiment_positive/negative', 'emotional', 'not_emotional'])\n",
    "#     if verbose:\n",
    "#         print(Counter(list(map(lambda x: rev_my_vocab[x], contain_valence[1]))).most_common(20))\n",
    "#     for tup in map_sent_valence:\n",
    "#             result.iloc[tup[0], :] += grouped.iloc[tup[1], 1:7] * grouped.iloc[tup[1], 7] / len(data[tup[0]].split())\n",
    "#     return result\n",
    "\n",
    "# X_train_banks_valence = valence_dataset(X_train_banks_pr_lm, True)\n",
    "# print()\n",
    "# X_test_banks_valence = valence_dataset(X_test_banks_pr_lm, True)\n",
    "\n",
    "# [('санкция', 700), ('потребительский', 350), ('вклад', 103), ('отзыв', 92), ('образец', 81), ('очередь', 63), ('помощь', 63), ('хороший', 60), ('поддержка', 48), ('признавать', 48), ('помогать', 44), ('долг', 36), ('операция', 34), ('мастер', 33), ('не работать', 33), ('льготный', 27), ('ошибка', 23), ('нужда', 23), ('сожаление', 22), ('надежный', 22)]\n",
    "\n",
    "# [('потребительский', 83), ('долг', 79), ('признавать', 69), ('шок', 64), ('банкрот', 60), ('иск', 58), ('банкротство', 51), ('кризис', 50), ('очередь', 49), ('помощь', 34), ('вклад', 32), ('убыток', 30), ('проблема', 29), ('поддержка', 23), ('не работать', 23), ('падение', 22), ('лидер', 22), ('льготный', 21), ('отказ', 21), ('хороший', 20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_banks_valence.to_csv(\"Corpuses/SentiRuEval/X_train_banks_valence.csv\", index=False)\n",
    "# X_test_banks_valence.to_csv(\"Corpuses/SentiRuEval/X_test_banks_valence.csv\", index=False)\n",
    "\n",
    "X_train_banks_valence = pd.read_csv(\"Corpuses/SentiRuEval/X_train_banks_valence.csv\")\n",
    "X_test_banks_valence = pd.read_csv(\"Corpuses/SentiRuEval/X_test_banks_valence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Результаты поиска по сетке будем сохранять в файлы в папку grid_results\n",
    "def save_grid(grid_res, name):\n",
    "    df = pd.DataFrame(grid_res.cv_results_).drop(['mean_fit_time', 'mean_score_time', 'mean_train_score',\n",
    "                                      'rank_test_score', 'split0_test_score', 'split0_train_score', \n",
    "                                       'split1_test_score', 'split1_train_score', 'split2_test_score', \n",
    "                                       'split2_train_score', 'std_fit_time', 'std_score_time', 'std_train_score'], 1, errors=\"ignore\")\n",
    "    df.sort_values(\"mean_test_score\", 0, ascending = False).reset_index().drop([\"index\"], 1).to_csv(\"grid_results/\"+name+\".csv\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "def read_grid(\n",
    "    name):\n",
    "    return pd.read_csv(\"grid_results/\"+name+\".csv\", sep=\";\", encoding=\"utf-8\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для выбора нужных признаков при предобработке\n",
    "\n",
    "class ColumnExtractor(object):\n",
    "\n",
    "    def __init__(self, rng):\n",
    "        self.rng = rng\n",
    "\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, \"values\"):\n",
    "            X = X.values\n",
    "        if self.rng[1] == \"end\":\n",
    "            return X[:, self.rng[0]:]\n",
    "        elif self.rng[1] == self.rng[0]:\n",
    "            return X[:, self.rng[0]]\n",
    "        else:\n",
    "            return X[:, self.rng[0]:self.rng[1]+1]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'rng' : self.rng}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.rng = value\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = metrics.make_scorer(metrics.f1_score, labels = [-1, 1], average = \"macro\")\n",
    "cv = model_selection.KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_short_lda5_valence = pd.concat([pd.DataFrame(X_train_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_train_banks_valence, X_train_banks_lda[5]], axis=1)\n",
    "# X_train_short_lda10_valence = pd.concat([pd.DataFrame(X_train_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_train_banks_valence, X_train_banks_lda[10]], axis=1)\n",
    "# X_train_short_lda20_valence = pd.concat([pd.DataFrame(X_train_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_train_banks_valence, X_train_banks_lda[20]], axis=1)\n",
    "\n",
    "# X_test_short_lda5_valence = pd.concat([pd.DataFrame(X_test_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_test_banks_valence, X_test_banks_lda[5]], axis=1)\n",
    "# X_test_short_lda10_valence = pd.concat([pd.DataFrame(X_test_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_test_banks_valence, X_test_banks_lda[10]], axis=1)\n",
    "# X_test_short_lda20_valence = pd.concat([pd.DataFrame(X_test_banks_pr_lm, columns = [[\"text\"]]), \n",
    "#                                         X_test_banks_valence, X_test_banks_lda[20]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_short_lda5_valence.to_csv(\"X_train_short_lda5_valence.csv\", index=False)\n",
    "# X_train_short_lda10_valence.to_csv(\"X_train_short_lda10_valence.csv\", index=False)\n",
    "# X_train_short_lda20_valence.to_csv(\"X_train_short_lda20_valence.csv\", index=False)\n",
    "\n",
    "# X_test_short_lda5_valence.to_csv(\"X_test_short_lda5_valence.csv\", index=False)\n",
    "# X_test_short_lda10_valence.to_csv(\"X_test_short_lda10_valence.csv\", index=False)\n",
    "# X_test_short_lda20_valence.to_csv(\"X_test_short_lda20_valence.csv\", index=False)\n",
    "\n",
    "X_train_short_lda5_valence = pd.read_csv(\"X_train_short_lda5_valence.csv\")\n",
    "X_train_short_lda10_valence = pd.read_csv(\"X_train_short_lda10_valence.csv\")\n",
    "X_train_short_lda20_valence = pd.read_csv(\"X_train_short_lda20_valence.csv\")\n",
    "\n",
    "X_test_short_lda5_valence = pd.read_csv(\"X_test_short_lda5_valence.csv\")\n",
    "X_test_short_lda10_valence = pd.read_csv(\"X_test_short_lda10_valence.csv\")\n",
    "X_test_short_lda20_valence = pd.read_csv(\"X_test_short_lda20_valence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sparse(x):\n",
    "    return sps.csr_matrix(x)\n",
    "\n",
    "# estimator = pipeline.Pipeline(steps = [       \n",
    "#     ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                               \n",
    "#             #text\n",
    "#             ('text_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([0, 0])),\n",
    "#                 ('vectorization', TfidfVectorizer()),\n",
    "#                         ])),\n",
    "#             #non-text\n",
    "#             ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "#                 ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "#                             ]))\n",
    "        \n",
    "#         ])),\n",
    "#        ('classifier', LinearSVC(random_state=42))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [None, [1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# ]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_short_lda5 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1)\n",
    "# grid_short_lda5.fit(X_train_short_lda5_valence, y_train_banks_naive)\n",
    "\n",
    "# save_grid(grid_short_lda5, \"FINAL_LINEAR_SVC_LDA5_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_short_lda10 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1)\n",
    "# grid_short_lda10.fit(X_train_short_lda10_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda10, \"FINAL_LINEAR_SVC_LDA10_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_short_lda20 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1)\n",
    "# grid_short_lda20.fit(X_train_short_lda20_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda20, \"FINAL_LINEAR_SVC_LDA20_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = pipeline.Pipeline(steps = [('vectorization', CountVectorizer()), ('classifier', LinearSVC(random_state = 42))])\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [None],\n",
    "#     'vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_s = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_s.fit(X_train_banks_pr_lm, y_train_banks_naive)\n",
    "# save_grid(grid_s, \"FINAL_LINEARSVC_BASE_RUN1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def return_sparse(x):\n",
    "#     return sps.csr_matrix(x)\n",
    "\n",
    "# estimator = pipeline.Pipeline(steps = [       \n",
    "#     ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                               \n",
    "#             #text\n",
    "#             ('text_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([0, 0])),\n",
    "#                 ('vectorization', TfidfVectorizer()),\n",
    "#                         ])),\n",
    "#             #non-text\n",
    "#             ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "#                 ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "#                             ]))\n",
    "        \n",
    "#         ])),\n",
    "#        ('classifier', LogisticRegression(random_state = 42, solver = \"newton-cg\", max_iter=500))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# # grid_short_lda5 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# # grid_short_lda5.fit(X_train_short_lda5_valence, y_train_banks_naive)\n",
    "# # save_grid(grid_short_lda5, \"FINAL_LOGISTIC_LDA5_RUN1\")\n",
    "\n",
    "# grid_short_lda10 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda10.fit(X_train_short_lda10_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda10, \"FINAL_LOGISTIC_LDA10_RUN1\")\n",
    "\n",
    "# grid_short_lda20 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda20.fit(X_train_short_lda20_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda20, \"FINAL_LOGISTIC_LDA20_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = pipeline.Pipeline(steps = [('vectorization', CountVectorizer()),\n",
    "#                               ('classifier', LogisticRegression(random_state = 42, solver = \"newton-cg\", max_iter=500))])\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [None],\n",
    "#     'vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_s = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_s.fit(X_train_banks_pr_lm, y_train_banks_naive)\n",
    "# save_grid(grid_s, \"FINAL_LOGISTIC_BASE_RUN1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_sparse(x):\n",
    "#     return sps.csr_matrix(x)\n",
    "\n",
    "# estimator = pipeline.Pipeline(steps = [       \n",
    "#     ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                               \n",
    "#             #text\n",
    "#             ('text_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([0, 0])),\n",
    "#                 ('vectorization', TfidfVectorizer()),\n",
    "#                         ])),\n",
    "#             #non-text\n",
    "#             ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "#                 ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "#                             ]))\n",
    "        \n",
    "#         ])),\n",
    "#        ('classifier', MultinomialNB())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [1]\n",
    "# },\n",
    "# {\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [2]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# grid_short_lda5 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda5.fit(X_train_short_lda5_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda5, \"FINAL_NB_LDA5_RUN1\")\n",
    "\n",
    "# grid_short_lda10 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda10.fit(X_train_short_lda10_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda10, \"  FINAL_NB_LDA10_RUN1\")\n",
    "\n",
    "# grid_short_lda20 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda20.fit(X_train_short_lda20_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda20, \"FINAL_NB_LDA20_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = pipeline.Pipeline(steps = [('vectorization', CountVectorizer()),\n",
    "#                               ('classifier', MultinomialNB())])\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'vectorization__min_df' : [1]\n",
    "# },\n",
    "# {\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [None],\n",
    "#     'vectorization__min_df' : [2]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_s = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "# grid_s.fit(X_train_banks_pr_lm, y_train_banks_naive)\n",
    "# save_grid(grid_s, \"FINAL_NB_BASE_RUN1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_sparse(x):\n",
    "#     return sps.csr_matrix(x)\n",
    "\n",
    "# estimator = pipeline.Pipeline(steps = [       \n",
    "#     ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                               \n",
    "#             #text\n",
    "#             ('text_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([0, 0])),\n",
    "#                 ('vectorization', TfidfVectorizer()),\n",
    "#                         ])),\n",
    "#             #non-text\n",
    "#             ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "#                 ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "#                             ]))\n",
    "        \n",
    "#         ])),\n",
    "#        ('classifier', RandomForestClassifier(n_estimators = 200, random_state = 42))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [1],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [2],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# grid_short_lda5 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=7, return_train_score=False)\n",
    "# grid_short_lda5.fit(X_train_short_lda5_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda5, \"FINAL_RF_LDA5_RUN1\")\n",
    "\n",
    "# grid_short_lda10 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=7, return_train_score=False)\n",
    "# grid_short_lda10.fit(X_train_short_lda10_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda10, \"FINAL_RF_LDA10_RUN1\")\n",
    "\n",
    "# grid_short_lda20 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=7, return_train_score=False)\n",
    "# grid_short_lda20.fit(X_train_short_lda20_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda20, \"FINAL_RF_LDA20_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = pipeline.Pipeline(steps = [('vectorization', CountVectorizer()),\n",
    "#                               ('classifier', RandomForestClassifier(n_estimators = 200, random_state = 42))])\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'vectorization__min_df' : [1],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [None],\n",
    "#     'vectorization__min_df' : [2],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_s = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "# grid_s.fit(X_train_banks_pr_lm, y_train_banks_naive)\n",
    "# save_grid(grid_s, \"FINAL_RF_BASE_RUN1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_sparse(x):\n",
    "#     return sps.csr_matrix(x)\n",
    "\n",
    "# estimator = pipeline.Pipeline(steps = [       \n",
    "#     ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                               \n",
    "#             #text\n",
    "#             ('text_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([0, 0])),\n",
    "#                 ('vectorization', TfidfVectorizer()),\n",
    "#                         ])),\n",
    "#             #non-text\n",
    "#             ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "#                 ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "#                 ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "#                             ]))\n",
    "        \n",
    "#         ])),\n",
    "#        ('classifier', SVC(random_state = 42))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'feature_processing__text_processing__vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'feature_processing__text_processing__vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'feature_processing__text_processing__vectorization__stop_words' : [None],\n",
    "#     'feature_processing__nontext_processing__selecting__rng' : [[1, 6], [7, \"end\"], [1, \"end\"]],\n",
    "#     'feature_processing__text_processing__vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# grid_short_lda5 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda5.fit(X_train_short_lda5_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda5, \"FINAL_SVC_LDA5_RUN1\")\n",
    "\n",
    "# grid_short_lda10 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda10.fit(X_train_short_lda10_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda10, \"FINAL_SVC_LDA10_RUN1\")\n",
    "\n",
    "# grid_short_lda20 = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "# grid_short_lda20.fit(X_train_short_lda20_valence, y_train_banks_naive)\n",
    "# save_grid(grid_short_lda20, \"FINAL_SVC_LDA20_RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# estimator = pipeline.Pipeline(steps = [('vectorization', CountVectorizer()),\n",
    "#                               ('classifier', SVC(random_state = 42))])\n",
    "\n",
    "# parameters_grid = [{\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [stop_words, author_stop_words, None],\n",
    "#     'vectorization__min_df' : [1],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# },\n",
    "# {\n",
    "#     'vectorization' : [CountVectorizer(), TfidfVectorizer()],\n",
    "#     'vectorization__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "#     'vectorization__stop_words' : [None],\n",
    "#     'vectorization__min_df' : [2],\n",
    "#     'classifier__C' : [0.1, 1, 10, 100],\n",
    "#     'classifier__class_weight' : [None, \"balanced\"]\n",
    "# }]\n",
    "\n",
    "# cv = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "# grid_s = model_selection.GridSearchCV(estimator, parameters_grid, scoring = scorer, cv = cv, verbose=True, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "# grid_s.fit(X_train_banks_pr_lm, y_train_banks_naive)\n",
    "# save_grid(grid_s, \"FINAL_SVC_BASE_RUN1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sw_slice(df, sw):\n",
    "    vec_prefix = \"param_vectorization__\" if \"param_vectorization__stop_words\" in df.columns else \"param_feature_processing__text_processing__vectorization__\"\n",
    "    if sw == \"no_sw\":\n",
    "        no_sw = df.loc[df[vec_prefix+\"stop_words\"].isna()]\n",
    "        return no_sw.loc[df[vec_prefix+\"min_df\"] == 1]\n",
    "    elif sw == \"author\":\n",
    "        with_sw = df.loc[df[vec_prefix+\"stop_words\"].notna()]\n",
    "        return with_sw.loc[with_sw[vec_prefix+\"stop_words\"].str.contains(\"москва\")]\n",
    "    elif sw == \"classic\":\n",
    "        with_sw = df.loc[df[vec_prefix+\"stop_words\"].notna()]\n",
    "        return with_sw.loc[~with_sw[vec_prefix+\"stop_words\"].str.contains(\"москва\")]\n",
    "    elif sw == \"singleton\":\n",
    "        no_sw = df.loc[df[vec_prefix+\"stop_words\"].isna()]\n",
    "        return no_sw.loc[df[vec_prefix+\"min_df\"] == 2]\n",
    "    else:\n",
    "        raise Exception(\"Wrong param name\")\n",
    "        \n",
    "def extract_feature_slice(df, rng):\n",
    "    return df.loc[df[\"param_feature_processing__nontext_processing__selecting__rng\"].map(lambda x: eval(x) == list(rng))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_best_model(best_model, model_type, sw, rng=None, LDA=None):\n",
    "    model_dict = {\"FINAL_LINEAR_SVC\": LinearSVC(random_state = 42), \n",
    "                  \"FINAL_LOGISTIC\": LogisticRegression(random_state = 42, solver = \"newton-cg\", max_iter=500),\n",
    "                  \"FINAL_NB\": MultinomialNB(),\n",
    "                  \"FINAL_RF\": RandomForestClassifier(n_estimators = 200, random_state = 42),\n",
    "                  \"FINAL_SVC\": SVC(random_state = 42)}\n",
    "    \n",
    "    if rng:\n",
    "        assert LDA\n",
    "        if LDA == \"LDA5\":\n",
    "            X_train = X_train_short_lda5_valence\n",
    "            X_test = X_test_short_lda5_valence\n",
    "        elif LDA == \"LDA10\":\n",
    "            X_train = X_train_short_lda10_valence\n",
    "            X_test = X_test_short_lda10_valence\n",
    "        else:\n",
    "            X_train = X_train_short_lda20_valence\n",
    "            X_test = X_test_short_lda20_valence\n",
    "    else:\n",
    "        X_train = X_train_banks_pr_lm\n",
    "        X_test = X_test_banks_pr_lm\n",
    "    \n",
    "    params = best_model.drop([\"mean_test_score\", \"params\", \"std_test_score\"]).to_dict()\n",
    "    params[\"param_classifier\"] = model_dict[model_type]\n",
    "    \n",
    "    if 'param_classifier__class_weight' in params:\n",
    "        if params['param_classifier__class_weight'] != \"balanced\":\n",
    "            params['param_classifier__class_weight'] = None\n",
    "    \n",
    "    if \"param_feature_processing__nontext_processing__selecting__rng\" in best_model:\n",
    "        assert rng\n",
    "        params[\"param_feature_processing__nontext_processing__selecting__rng\"] = list(rng)\n",
    "        estimator = pipeline.Pipeline(steps = [       \n",
    "            ('param_feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "\n",
    "                    #text\n",
    "                    ('text_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', ColumnExtractor([0, 0])),\n",
    "                        ('vectorization', TfidfVectorizer()),\n",
    "                                ])),\n",
    "                    #non-text\n",
    "                    ('nontext_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', ColumnExtractor([1,\"end\"])),\n",
    "                        ('return_sparcity', preprocessing.FunctionTransformer(return_sparse))\n",
    "                                    ]))\n",
    "\n",
    "                ])),\n",
    "               ('param_classifier', LinearSVC(random_state=42))\n",
    "            ]\n",
    "        )\n",
    "        vec_prefix = 'param_feature_processing__text_processing__'\n",
    "    else:\n",
    "        estimator = pipeline.Pipeline(steps = [('param_vectorization', CountVectorizer()), ('param_classifier', LinearSVC(random_state = 42))])\n",
    "        vec_prefix = 'param_'\n",
    "        \n",
    "    if re.search(\"TfidfVectorizer\", params[vec_prefix+'vectorization']):\n",
    "        params[vec_prefix+'vectorization'] = TfidfVectorizer()\n",
    "    elif re.search(\"CountVectorizer\", params[vec_prefix+'vectorization']):\n",
    "        params[vec_prefix+'vectorization'] = CountVectorizer()\n",
    "        \n",
    "    params[vec_prefix+\"vectorization__ngram_range\"] = (int(params[vec_prefix+\"vectorization__ngram_range\"][1]),\n",
    "                                                       int(params[vec_prefix+\"vectorization__ngram_range\"][4]))\n",
    "    \n",
    "    if sw == \"no_sw\":\n",
    "        params[vec_prefix+\"vectorization__stop_words\"] = None\n",
    "    elif sw == \"author\":\n",
    "        params[vec_prefix+\"vectorization__stop_words\"] = author_stop_words\n",
    "    elif sw == \"classic\":\n",
    "        params[vec_prefix+\"vectorization__stop_words\"] = stop_words\n",
    "    elif sw == \"singleton\":\n",
    "        params[vec_prefix+\"vectorization__stop_words\"] = None\n",
    "        params[vec_prefix+\"vectorization__min_df\"] = 2\n",
    "    else:\n",
    "        raise Exception(\"Wrong param name\")\n",
    "    \n",
    "    estimator.set_params(**params)\n",
    "    estimator.fit(X_train, y_train_banks_naive)\n",
    "    prediction = estimator.predict(X_test)\n",
    "    return f_measure2(y_test_banks, prediction)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_result(sw=\"no_sw\", validation=False):\n",
    "    template = pd.DataFrame(index=[\"LinearSVC\", \"LogReg\", \"RF\", \"NB\", \"SVC RBF\"], \n",
    "                            columns=[\"basic\", \"basic + SD\", \"basic + LDA5\", \"basic + LDA10\", \"basic + LDA20\", \"basic + LDA5 + SD\", \"basic + LDA10 + SD\", \"basic + LDA20 + SD\"])\n",
    "    models = [\"FINAL_LINEAR_SVC\", \"FINAL_LOGISTIC\", \"FINAL_NB\", \"FINAL_RF\", \"FINAL_SVC\"]\n",
    "    model_dict = {\"FINAL_LINEAR_SVC\": \"LinearSVC\", \n",
    "                  \"FINAL_LOGISTIC\": \"LogReg\",\n",
    "                  \"FINAL_NB\": \"NB\",\n",
    "                  \"FINAL_RF\": \"RF\",\n",
    "                  \"FINAL_SVC\": \"SVC RBF\"}\n",
    "    \n",
    "    feature_dict = {(7, \"end\") : \"basic + {}\", \n",
    "                    (1, \"end\") :\"basic + {} + SD\"}\n",
    "    ending = \"RUN1\"\n",
    "    for model_type in models:\n",
    "        df = read_grid(\"_\".join([model_type, \"BASE\", ending]))\n",
    "        sw_slice = extract_sw_slice(df, sw)\n",
    "        best_model = sw_slice.loc[sw_slice[\"mean_test_score\"].idxmax()]\n",
    "        res = best_model[\"mean_test_score\"] if not validation else estimate_best_model(best_model, model_type, sw)\n",
    "        template[\"basic\"][model_dict[model_type]] = res\n",
    "        \n",
    "        df = read_grid(\"_\".join([model_type, \"LDA5\", ending]))\n",
    "        sw_slice = extract_sw_slice(df, sw)\n",
    "        feature_slice = extract_feature_slice(sw_slice, (1, 6))\n",
    "        best_model = feature_slice.loc[feature_slice[\"mean_test_score\"].idxmax()]\n",
    "        res = best_model[\"mean_test_score\"] if not validation else estimate_best_model(best_model, model_type, sw, (1, 6), \"LDA5\")\n",
    "        template[\"basic + SD\"][model_dict[model_type]] = res\n",
    "        \n",
    "        for feature in [\"LDA5\", \"LDA10\", \"LDA20\"]:\n",
    "            df = read_grid(\"_\".join([model_type, feature, ending]))\n",
    "            sw_slice = extract_sw_slice(df, sw)\n",
    "            for rng in feature_dict.keys():\n",
    "                feature_slice = extract_feature_slice(sw_slice, rng)\n",
    "                best_model = feature_slice.loc[feature_slice[\"mean_test_score\"].idxmax()]\n",
    "                res = best_model[\"mean_test_score\"] if not validation else estimate_best_model(best_model, model_type, sw, rng, feature)\n",
    "                template[feature_dict[rng].format(feature)][model_dict[model_type]] = res\n",
    "    template[\"Mean\"] = template.mean(axis=1)\n",
    "    template.loc[\"Mean\"] = template.mean(axis=0)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "cv_no_sw, cv_classic, cv_singleton, cv_author = \\\n",
    "pool.starmap(construct_result, [(\"no_sw\", False),\n",
    "                                (\"classic\", False),\n",
    "                                (\"singleton\", False),\n",
    "                                (\"author\", False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.715124</td>\n",
       "      <td>0.727012</td>\n",
       "      <td>0.71644</td>\n",
       "      <td>0.71905</td>\n",
       "      <td>0.718788</td>\n",
       "      <td>0.727866</td>\n",
       "      <td>0.730074</td>\n",
       "      <td>0.728771</td>\n",
       "      <td>0.722891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.717661</td>\n",
       "      <td>0.731491</td>\n",
       "      <td>0.716919</td>\n",
       "      <td>0.718237</td>\n",
       "      <td>0.720237</td>\n",
       "      <td>0.73074</td>\n",
       "      <td>0.729371</td>\n",
       "      <td>0.730709</td>\n",
       "      <td>0.724421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.63953</td>\n",
       "      <td>0.645397</td>\n",
       "      <td>0.618179</td>\n",
       "      <td>0.628821</td>\n",
       "      <td>0.625033</td>\n",
       "      <td>0.633912</td>\n",
       "      <td>0.645498</td>\n",
       "      <td>0.645998</td>\n",
       "      <td>0.635296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.65927</td>\n",
       "      <td>0.653463</td>\n",
       "      <td>0.645815</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.647229</td>\n",
       "      <td>0.646663</td>\n",
       "      <td>0.652203</td>\n",
       "      <td>0.646845</td>\n",
       "      <td>0.650519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.648685</td>\n",
       "      <td>0.646391</td>\n",
       "      <td>0.637559</td>\n",
       "      <td>0.626515</td>\n",
       "      <td>0.628615</td>\n",
       "      <td>0.641391</td>\n",
       "      <td>0.636441</td>\n",
       "      <td>0.640701</td>\n",
       "      <td>0.638287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.676054</td>\n",
       "      <td>0.680751</td>\n",
       "      <td>0.666982</td>\n",
       "      <td>0.669057</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.676114</td>\n",
       "      <td>0.678717</td>\n",
       "      <td>0.678605</td>\n",
       "      <td>0.674283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.715124   0.727012      0.71644       0.71905      0.718788   \n",
       "LogReg     0.717661   0.731491     0.716919      0.718237      0.720237   \n",
       "RF          0.63953   0.645397     0.618179      0.628821      0.625033   \n",
       "NB          0.65927   0.653463     0.645815      0.652661      0.647229   \n",
       "SVC RBF    0.648685   0.646391     0.637559      0.626515      0.628615   \n",
       "Mean       0.676054   0.680751     0.666982      0.669057       0.66798   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.727866           0.730074           0.728771  0.722891  \n",
       "LogReg              0.73074           0.729371           0.730709  0.724421  \n",
       "RF                 0.633912           0.645498           0.645998  0.635296  \n",
       "NB                 0.646663           0.652203           0.646845  0.650519  \n",
       "SVC RBF            0.641391           0.636441           0.640701  0.638287  \n",
       "Mean               0.676114           0.678717           0.678605  0.674283  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_no_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.701681</td>\n",
       "      <td>0.716003</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.708954</td>\n",
       "      <td>0.708871</td>\n",
       "      <td>0.716952</td>\n",
       "      <td>0.716903</td>\n",
       "      <td>0.720669</td>\n",
       "      <td>0.711992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.702961</td>\n",
       "      <td>0.719941</td>\n",
       "      <td>0.702708</td>\n",
       "      <td>0.699382</td>\n",
       "      <td>0.714049</td>\n",
       "      <td>0.717154</td>\n",
       "      <td>0.710678</td>\n",
       "      <td>0.718564</td>\n",
       "      <td>0.710680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.641396</td>\n",
       "      <td>0.646712</td>\n",
       "      <td>0.609078</td>\n",
       "      <td>0.612338</td>\n",
       "      <td>0.617462</td>\n",
       "      <td>0.633972</td>\n",
       "      <td>0.641401</td>\n",
       "      <td>0.643327</td>\n",
       "      <td>0.630711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.657686</td>\n",
       "      <td>0.650708</td>\n",
       "      <td>0.646595</td>\n",
       "      <td>0.644445</td>\n",
       "      <td>0.647589</td>\n",
       "      <td>0.645579</td>\n",
       "      <td>0.642858</td>\n",
       "      <td>0.649321</td>\n",
       "      <td>0.648098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.634685</td>\n",
       "      <td>0.640699</td>\n",
       "      <td>0.626442</td>\n",
       "      <td>0.610825</td>\n",
       "      <td>0.617794</td>\n",
       "      <td>0.633433</td>\n",
       "      <td>0.623277</td>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.627072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.667682</td>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.658146</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.669418</td>\n",
       "      <td>0.667023</td>\n",
       "      <td>0.67226</td>\n",
       "      <td>0.665711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.701681   0.716003     0.705907      0.708954      0.708871   \n",
       "LogReg     0.702961   0.719941     0.702708      0.699382      0.714049   \n",
       "RF         0.641396   0.646712     0.609078      0.612338      0.617462   \n",
       "NB         0.657686   0.650708     0.646595      0.644445      0.647589   \n",
       "SVC RBF    0.634685   0.640699     0.626442      0.610825      0.617794   \n",
       "Mean       0.667682   0.674813     0.658146      0.655189      0.661153   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.716952           0.716903           0.720669  0.711992  \n",
       "LogReg             0.717154           0.710678           0.718564  0.710680  \n",
       "RF                 0.633972           0.641401           0.643327  0.630711  \n",
       "NB                 0.645579           0.642858           0.649321  0.648098  \n",
       "SVC RBF            0.633433           0.623277           0.629421  0.627072  \n",
       "Mean               0.669418           0.667023            0.67226  0.665711  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.697123</td>\n",
       "      <td>0.720586</td>\n",
       "      <td>0.707557</td>\n",
       "      <td>0.706147</td>\n",
       "      <td>0.707466</td>\n",
       "      <td>0.723306</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>0.714364</td>\n",
       "      <td>0.711642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.703211</td>\n",
       "      <td>0.716056</td>\n",
       "      <td>0.703807</td>\n",
       "      <td>0.70125</td>\n",
       "      <td>0.707319</td>\n",
       "      <td>0.715112</td>\n",
       "      <td>0.711962</td>\n",
       "      <td>0.716351</td>\n",
       "      <td>0.709384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.650372</td>\n",
       "      <td>0.660286</td>\n",
       "      <td>0.634963</td>\n",
       "      <td>0.645901</td>\n",
       "      <td>0.651354</td>\n",
       "      <td>0.644187</td>\n",
       "      <td>0.655222</td>\n",
       "      <td>0.658146</td>\n",
       "      <td>0.650054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.671408</td>\n",
       "      <td>0.665686</td>\n",
       "      <td>0.662867</td>\n",
       "      <td>0.665612</td>\n",
       "      <td>0.667897</td>\n",
       "      <td>0.664559</td>\n",
       "      <td>0.666974</td>\n",
       "      <td>0.668121</td>\n",
       "      <td>0.666640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.668892</td>\n",
       "      <td>0.66302</td>\n",
       "      <td>0.653588</td>\n",
       "      <td>0.652698</td>\n",
       "      <td>0.646436</td>\n",
       "      <td>0.66189</td>\n",
       "      <td>0.658524</td>\n",
       "      <td>0.659275</td>\n",
       "      <td>0.658040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.678201</td>\n",
       "      <td>0.685127</td>\n",
       "      <td>0.672556</td>\n",
       "      <td>0.674322</td>\n",
       "      <td>0.676094</td>\n",
       "      <td>0.681811</td>\n",
       "      <td>0.681853</td>\n",
       "      <td>0.683251</td>\n",
       "      <td>0.679152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.697123   0.720586     0.707557      0.706147      0.707466   \n",
       "LogReg     0.703211   0.716056     0.703807       0.70125      0.707319   \n",
       "RF         0.650372   0.660286     0.634963      0.645901      0.651354   \n",
       "NB         0.671408   0.665686     0.662867      0.665612      0.667897   \n",
       "SVC RBF    0.668892    0.66302     0.653588      0.652698      0.646436   \n",
       "Mean       0.678201   0.685127     0.672556      0.674322      0.676094   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.723306           0.716585           0.714364  0.711642  \n",
       "LogReg             0.715112           0.711962           0.716351  0.709384  \n",
       "RF                 0.644187           0.655222           0.658146  0.650054  \n",
       "NB                 0.664559           0.666974           0.668121  0.666640  \n",
       "SVC RBF             0.66189           0.658524           0.659275  0.658040  \n",
       "Mean               0.681811           0.681853           0.683251  0.679152  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.70748</td>\n",
       "      <td>0.723908</td>\n",
       "      <td>0.722568</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>0.714049</td>\n",
       "      <td>0.726954</td>\n",
       "      <td>0.726434</td>\n",
       "      <td>0.719937</td>\n",
       "      <td>0.719694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.705982</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>0.716625</td>\n",
       "      <td>0.70772</td>\n",
       "      <td>0.715309</td>\n",
       "      <td>0.728774</td>\n",
       "      <td>0.717516</td>\n",
       "      <td>0.723233</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.649207</td>\n",
       "      <td>0.655225</td>\n",
       "      <td>0.623132</td>\n",
       "      <td>0.621231</td>\n",
       "      <td>0.626658</td>\n",
       "      <td>0.640389</td>\n",
       "      <td>0.644513</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>0.638165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.663423</td>\n",
       "      <td>0.654802</td>\n",
       "      <td>0.642802</td>\n",
       "      <td>0.645143</td>\n",
       "      <td>0.645453</td>\n",
       "      <td>0.643604</td>\n",
       "      <td>0.646202</td>\n",
       "      <td>0.64531</td>\n",
       "      <td>0.648342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.647945</td>\n",
       "      <td>0.648139</td>\n",
       "      <td>0.633097</td>\n",
       "      <td>0.634382</td>\n",
       "      <td>0.63189</td>\n",
       "      <td>0.641402</td>\n",
       "      <td>0.640897</td>\n",
       "      <td>0.641388</td>\n",
       "      <td>0.639893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.674807</td>\n",
       "      <td>0.681929</td>\n",
       "      <td>0.667645</td>\n",
       "      <td>0.664939</td>\n",
       "      <td>0.666672</td>\n",
       "      <td>0.676225</td>\n",
       "      <td>0.675113</td>\n",
       "      <td>0.674966</td>\n",
       "      <td>0.672787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC   0.70748   0.723908     0.722568      0.716221      0.714049   \n",
       "LogReg     0.705982   0.727574     0.716625       0.70772      0.715309   \n",
       "RF         0.649207   0.655225     0.623132      0.621231      0.626658   \n",
       "NB         0.663423   0.654802     0.642802      0.645143      0.645453   \n",
       "SVC RBF    0.647945   0.648139     0.633097      0.634382       0.63189   \n",
       "Mean       0.674807   0.681929     0.667645      0.664939      0.666672   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.726954           0.726434           0.719937  0.719694  \n",
       "LogReg             0.728774           0.717516           0.723233  0.717842  \n",
       "RF                 0.640389           0.644513           0.644963  0.638165  \n",
       "NB                 0.643604           0.646202            0.64531  0.648342  \n",
       "SVC RBF            0.641402           0.640897           0.641388  0.639893  \n",
       "Mean               0.676225           0.675113           0.674966  0.672787  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "validation_no_sw, validation_classic, validation_singleton, validation_author = \\\n",
    "pool.starmap(construct_result, [(\"no_sw\", True),\n",
    "                                (\"classic\", True),\n",
    "                                (\"singleton\", True),\n",
    "                                (\"author\", True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.529459</td>\n",
       "      <td>0.543289</td>\n",
       "      <td>0.533748</td>\n",
       "      <td>0.542319</td>\n",
       "      <td>0.519864</td>\n",
       "      <td>0.527993</td>\n",
       "      <td>0.545574</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>0.535502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.527917</td>\n",
       "      <td>0.531284</td>\n",
       "      <td>0.535665</td>\n",
       "      <td>0.528241</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.533726</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>0.537408</td>\n",
       "      <td>0.533163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.401238</td>\n",
       "      <td>0.335715</td>\n",
       "      <td>0.333656</td>\n",
       "      <td>0.350274</td>\n",
       "      <td>0.377619</td>\n",
       "      <td>0.380108</td>\n",
       "      <td>0.414212</td>\n",
       "      <td>0.378202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.429258</td>\n",
       "      <td>0.459436</td>\n",
       "      <td>0.417701</td>\n",
       "      <td>0.424422</td>\n",
       "      <td>0.424042</td>\n",
       "      <td>0.42099</td>\n",
       "      <td>0.424523</td>\n",
       "      <td>0.424688</td>\n",
       "      <td>0.428132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.476651</td>\n",
       "      <td>0.477544</td>\n",
       "      <td>0.466641</td>\n",
       "      <td>0.473462</td>\n",
       "      <td>0.464853</td>\n",
       "      <td>0.471766</td>\n",
       "      <td>0.473814</td>\n",
       "      <td>0.475959</td>\n",
       "      <td>0.472586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.479216</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.457894</td>\n",
       "      <td>0.46042</td>\n",
       "      <td>0.459053</td>\n",
       "      <td>0.466419</td>\n",
       "      <td>0.471769</td>\n",
       "      <td>0.478808</td>\n",
       "      <td>0.469517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.529459   0.543289     0.533748      0.542319      0.519864   \n",
       "LogReg     0.527917   0.531284     0.535665      0.528241      0.536232   \n",
       "RF         0.432793   0.401238     0.335715      0.333656      0.350274   \n",
       "NB         0.429258   0.459436     0.417701      0.424422      0.424042   \n",
       "SVC RBF    0.476651   0.477544     0.466641      0.473462      0.464853   \n",
       "Mean       0.479216   0.482558     0.457894       0.46042      0.459053   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.527993           0.545574           0.541773  0.535502  \n",
       "LogReg             0.533726           0.534828           0.537408  0.533163  \n",
       "RF                 0.377619           0.380108           0.414212  0.378202  \n",
       "NB                  0.42099           0.424523           0.424688  0.428132  \n",
       "SVC RBF            0.471766           0.473814           0.475959  0.472586  \n",
       "Mean               0.466419           0.471769           0.478808  0.469517  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_no_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.532857</td>\n",
       "      <td>0.527019</td>\n",
       "      <td>0.509118</td>\n",
       "      <td>0.525838</td>\n",
       "      <td>0.535932</td>\n",
       "      <td>0.535624</td>\n",
       "      <td>0.515388</td>\n",
       "      <td>0.52556</td>\n",
       "      <td>0.525917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.520406</td>\n",
       "      <td>0.518282</td>\n",
       "      <td>0.52307</td>\n",
       "      <td>0.51192</td>\n",
       "      <td>0.521516</td>\n",
       "      <td>0.524854</td>\n",
       "      <td>0.52569</td>\n",
       "      <td>0.518463</td>\n",
       "      <td>0.520525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.399776</td>\n",
       "      <td>0.418713</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>0.302464</td>\n",
       "      <td>0.366346</td>\n",
       "      <td>0.408348</td>\n",
       "      <td>0.393376</td>\n",
       "      <td>0.41451</td>\n",
       "      <td>0.378704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.428646</td>\n",
       "      <td>0.453639</td>\n",
       "      <td>0.44004</td>\n",
       "      <td>0.457209</td>\n",
       "      <td>0.443576</td>\n",
       "      <td>0.444424</td>\n",
       "      <td>0.456011</td>\n",
       "      <td>0.446341</td>\n",
       "      <td>0.446236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.467343</td>\n",
       "      <td>0.483401</td>\n",
       "      <td>0.454697</td>\n",
       "      <td>0.45427</td>\n",
       "      <td>0.452236</td>\n",
       "      <td>0.464964</td>\n",
       "      <td>0.470948</td>\n",
       "      <td>0.469192</td>\n",
       "      <td>0.464631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.469806</td>\n",
       "      <td>0.480211</td>\n",
       "      <td>0.450605</td>\n",
       "      <td>0.45034</td>\n",
       "      <td>0.463921</td>\n",
       "      <td>0.475643</td>\n",
       "      <td>0.472282</td>\n",
       "      <td>0.474813</td>\n",
       "      <td>0.467203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.532857   0.527019     0.509118      0.525838      0.535932   \n",
       "LogReg     0.520406   0.518282      0.52307       0.51192      0.521516   \n",
       "RF         0.399776   0.418713     0.326097      0.302464      0.366346   \n",
       "NB         0.428646   0.453639      0.44004      0.457209      0.443576   \n",
       "SVC RBF    0.467343   0.483401     0.454697       0.45427      0.452236   \n",
       "Mean       0.469806   0.480211     0.450605       0.45034      0.463921   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.535624           0.515388            0.52556  0.525917  \n",
       "LogReg             0.524854            0.52569           0.518463  0.520525  \n",
       "RF                 0.408348           0.393376            0.41451  0.378704  \n",
       "NB                 0.444424           0.456011           0.446341  0.446236  \n",
       "SVC RBF            0.464964           0.470948           0.469192  0.464631  \n",
       "Mean               0.475643           0.472282           0.474813  0.467203  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.513005</td>\n",
       "      <td>0.53409</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.527564</td>\n",
       "      <td>0.524659</td>\n",
       "      <td>0.536973</td>\n",
       "      <td>0.529982</td>\n",
       "      <td>0.530028</td>\n",
       "      <td>0.527706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.53008</td>\n",
       "      <td>0.533543</td>\n",
       "      <td>0.499298</td>\n",
       "      <td>0.527558</td>\n",
       "      <td>0.524337</td>\n",
       "      <td>0.528987</td>\n",
       "      <td>0.530807</td>\n",
       "      <td>0.536322</td>\n",
       "      <td>0.526367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.429134</td>\n",
       "      <td>0.415617</td>\n",
       "      <td>0.389217</td>\n",
       "      <td>0.379944</td>\n",
       "      <td>0.41793</td>\n",
       "      <td>0.413138</td>\n",
       "      <td>0.422981</td>\n",
       "      <td>0.401002</td>\n",
       "      <td>0.408621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.483848</td>\n",
       "      <td>0.484527</td>\n",
       "      <td>0.490974</td>\n",
       "      <td>0.470952</td>\n",
       "      <td>0.470113</td>\n",
       "      <td>0.492867</td>\n",
       "      <td>0.470805</td>\n",
       "      <td>0.471166</td>\n",
       "      <td>0.479407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.501413</td>\n",
       "      <td>0.490181</td>\n",
       "      <td>0.471169</td>\n",
       "      <td>0.494563</td>\n",
       "      <td>0.466564</td>\n",
       "      <td>0.501396</td>\n",
       "      <td>0.493809</td>\n",
       "      <td>0.490656</td>\n",
       "      <td>0.488719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.491496</td>\n",
       "      <td>0.491592</td>\n",
       "      <td>0.475202</td>\n",
       "      <td>0.480116</td>\n",
       "      <td>0.480721</td>\n",
       "      <td>0.494672</td>\n",
       "      <td>0.489677</td>\n",
       "      <td>0.485835</td>\n",
       "      <td>0.486164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.513005    0.53409     0.525351      0.527564      0.524659   \n",
       "LogReg      0.53008   0.533543     0.499298      0.527558      0.524337   \n",
       "RF         0.429134   0.415617     0.389217      0.379944       0.41793   \n",
       "NB         0.483848   0.484527     0.490974      0.470952      0.470113   \n",
       "SVC RBF    0.501413   0.490181     0.471169      0.494563      0.466564   \n",
       "Mean       0.491496   0.491592     0.475202      0.480116      0.480721   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.536973           0.529982           0.530028  0.527706  \n",
       "LogReg             0.528987           0.530807           0.536322  0.526367  \n",
       "RF                 0.413138           0.422981           0.401002  0.408621  \n",
       "NB                 0.492867           0.470805           0.471166  0.479407  \n",
       "SVC RBF            0.501396           0.493809           0.490656  0.488719  \n",
       "Mean               0.494672           0.489677           0.485835  0.486164  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>basic + SD</th>\n",
       "      <th>basic + LDA5</th>\n",
       "      <th>basic + LDA10</th>\n",
       "      <th>basic + LDA20</th>\n",
       "      <th>basic + LDA5 + SD</th>\n",
       "      <th>basic + LDA10 + SD</th>\n",
       "      <th>basic + LDA20 + SD</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.557408</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>0.551835</td>\n",
       "      <td>0.556255</td>\n",
       "      <td>0.542824</td>\n",
       "      <td>0.560074</td>\n",
       "      <td>0.561638</td>\n",
       "      <td>0.550236</td>\n",
       "      <td>0.555575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.546189</td>\n",
       "      <td>0.548207</td>\n",
       "      <td>0.545627</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.540403</td>\n",
       "      <td>0.547053</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>0.553598</td>\n",
       "      <td>0.545868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.461101</td>\n",
       "      <td>0.422583</td>\n",
       "      <td>0.336412</td>\n",
       "      <td>0.302538</td>\n",
       "      <td>0.35431</td>\n",
       "      <td>0.38124</td>\n",
       "      <td>0.372831</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.379606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.44631</td>\n",
       "      <td>0.448904</td>\n",
       "      <td>0.473781</td>\n",
       "      <td>0.43609</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.474958</td>\n",
       "      <td>0.440446</td>\n",
       "      <td>0.478164</td>\n",
       "      <td>0.459017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC RBF</th>\n",
       "      <td>0.478777</td>\n",
       "      <td>0.485223</td>\n",
       "      <td>0.479305</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.465629</td>\n",
       "      <td>0.475838</td>\n",
       "      <td>0.477158</td>\n",
       "      <td>0.477323</td>\n",
       "      <td>0.475666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.497957</td>\n",
       "      <td>0.49385</td>\n",
       "      <td>0.477392</td>\n",
       "      <td>0.461245</td>\n",
       "      <td>0.47533</td>\n",
       "      <td>0.487833</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>0.493031</td>\n",
       "      <td>0.483147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              basic basic + SD basic + LDA5 basic + LDA10 basic + LDA20  \\\n",
       "LinearSVC  0.557408   0.564333     0.551835      0.556255      0.542824   \n",
       "LogReg     0.546189   0.548207     0.545627      0.545271      0.540403   \n",
       "RF         0.461101   0.422583     0.336412      0.302538       0.35431   \n",
       "NB          0.44631   0.448904     0.473781       0.43609      0.473485   \n",
       "SVC RBF    0.478777   0.485223     0.479305      0.466071      0.465629   \n",
       "Mean       0.497957    0.49385     0.477392      0.461245       0.47533   \n",
       "\n",
       "          basic + LDA5 + SD basic + LDA10 + SD basic + LDA20 + SD      Mean  \n",
       "LinearSVC          0.560074           0.561638           0.550236  0.555575  \n",
       "LogReg             0.547053             0.5406           0.553598  0.545868  \n",
       "RF                  0.38124           0.372831           0.405836  0.379606  \n",
       "NB                 0.474958           0.440446           0.478164  0.459017  \n",
       "SVC RBF            0.475838           0.477158           0.477323  0.475666  \n",
       "Mean               0.487833           0.478535           0.493031  0.483147  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_author"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
